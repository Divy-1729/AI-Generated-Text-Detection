{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2250642,"sourceType":"datasetVersion","datasetId":1075326},{"sourceId":7706709,"sourceType":"datasetVersion","datasetId":4499487},{"sourceId":10388697,"sourceType":"datasetVersion","datasetId":6436158},{"sourceId":7379779,"sourceType":"datasetVersion","datasetId":4288635}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# Input data files are available in the read-only \"../input/\" directory\n\n# For example, running this (by clickingrun or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:08:05.151106Z","iopub.execute_input":"2025-02-20T22:08:05.151359Z","iopub.status.idle":"2025-02-20T22:08:05.463632Z","shell.execute_reply.started":"2025-02-20T22:08:05.151335Z","shell.execute_reply":"2025-02-20T22:08:05.462765Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ai-vs-human-text/AI_Human.csv\n/kaggle/input/suicidewatch/SuicideWatch.csv\n/kaggle/input/suicidal-mental-health-dataset/mental-health.csv\n/kaggle/input/suicide-watch/Suicide_Detection.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nfrom keras import layers, optimizers\n\nfrom keras_hub.tokenizers import WordPieceTokenizer, compute_word_piece_vocabulary\n\nfrom keras_hub.layers import TokenAndPositionEmbedding, FNetEncoder\n\nimport keras_tuner as kt\n\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:08:05.464428Z","iopub.execute_input":"2025-02-20T22:08:05.464876Z","iopub.status.idle":"2025-02-20T22:08:15.908560Z","shell.execute_reply.started":"2025-02-20T22:08:05.464843Z","shell.execute_reply":"2025-02-20T22:08:15.907668Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/ai-vs-human-text/AI_Human.csv')\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:08:22.041655Z","iopub.execute_input":"2025-02-20T22:08:22.041983Z","iopub.status.idle":"2025-02-20T22:08:45.233696Z","shell.execute_reply.started":"2025-02-20T22:08:22.041957Z","shell.execute_reply":"2025-02-20T22:08:45.232949Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                     text  generated\n0       Cars. Cars have been around since they became ...        0.0\n1       Transportation is a large necessity in most co...        0.0\n2       \"America's love affair with it's vehicles seem...        0.0\n3       How often do you ride in a car? Do you drive a...        0.0\n4       Cars are a wonderful thing. They are perhaps o...        0.0\n...                                                   ...        ...\n487230  Tie Face on Mars is really just a big misunder...        0.0\n487231  The whole purpose of democracy is to create a ...        0.0\n487232  I firmly believe that governments worldwide sh...        1.0\n487233  I DFN't agree with this decision because a LFT...        0.0\n487234  Richard Non, Jimmy Carter, and Bob Dole and ot...        0.0\n\n[487235 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>487230</th>\n      <td>Tie Face on Mars is really just a big misunder...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>487231</th>\n      <td>The whole purpose of democracy is to create a ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>487232</th>\n      <td>I firmly believe that governments worldwide sh...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>487233</th>\n      <td>I DFN't agree with this decision because a LFT...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>487234</th>\n      <td>Richard Non, Jimmy Carter, and Bob Dole and ot...</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>487235 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df=df.rename({'generated' : 'class'}, axis = 1)\ndf.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:08:50.440624Z","iopub.execute_input":"2025-02-20T22:08:50.440900Z","iopub.status.idle":"2025-02-20T22:08:50.464137Z","shell.execute_reply.started":"2025-02-20T22:08:50.440878Z","shell.execute_reply":"2025-02-20T22:08:50.463164Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(487235, 2)"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train_df, other = train_test_split(\n    df,\n    test_size = 0.1,\n    random_state = 9730,\n    shuffle = True,\n    stratify = df['class'],\n)\n\nval_df, test_df = train_test_split(\n    other,\n    test_size = 0.5,\n    random_state = 9730,\n    shuffle = True,\n    stratify = other['class'],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:08:55.393415Z","iopub.execute_input":"2025-02-20T22:08:55.393690Z","iopub.status.idle":"2025-02-20T22:08:55.630297Z","shell.execute_reply.started":"2025-02-20T22:08:55.393668Z","shell.execute_reply":"2025-02-20T22:08:55.629608Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices(\n    (train_df['text'].values, train_df['class'].values)\n)\n\nval_dataset = tf.data.Dataset.from_tensor_slices(\n    (val_df['text'].values, val_df['class'].values)\n)\n\ntest_dataset = tf.data.Dataset.from_tensor_slices(\n    (test_df['text'].values, test_df['class'].values)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:08:57.222798Z","iopub.execute_input":"2025-02-20T22:08:57.223086Z","iopub.status.idle":"2025-02-20T22:08:59.912528Z","shell.execute_reply.started":"2025-02-20T22:08:57.223065Z","shell.execute_reply":"2025-02-20T22:08:59.911469Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# convert the text to lowercase\ntrain_dataset = train_dataset.map(lambda text, label: (tf.strings.lower(text), label))\nval_dataset = val_dataset.map(lambda text, label: (tf.strings.lower(text), label))\ntest_dataset = test_dataset.map(lambda text, label: (tf.strings.lower(text), label))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:09:01.102957Z","iopub.execute_input":"2025-02-20T22:09:01.103389Z","iopub.status.idle":"2025-02-20T22:09:01.182046Z","shell.execute_reply.started":"2025-02-20T22:09:01.103353Z","shell.execute_reply":"2025-02-20T22:09:01.181168Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"BATCH_SIZE = 16\nMAX_SEQLEN = 512\nauto = tf.data.AUTOTUNE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:09:03.916962Z","iopub.execute_input":"2025-02-20T22:09:03.917294Z","iopub.status.idle":"2025-02-20T22:09:03.921054Z","shell.execute_reply.started":"2025-02-20T22:09:03.917264Z","shell.execute_reply":"2025-02-20T22:09:03.920198Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(auto)\nval_dataset = val_dataset.batch(BATCH_SIZE).prefetch(auto)\ntest_dataset = test_dataset.batch(BATCH_SIZE).prefetch(auto)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:09:05.599606Z","iopub.execute_input":"2025-02-20T22:09:05.599914Z","iopub.status.idle":"2025-02-20T22:09:05.615479Z","shell.execute_reply.started":"2025-02-20T22:09:05.599886Z","shell.execute_reply":"2025-02-20T22:09:05.614542Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"for text_batch, label_batch in train_dataset.take(1):\n    for i in range(3):\n        print(f\"{text_batch.numpy()[i]}\\n{label_batch.numpy()[i]}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:09:07.093369Z","iopub.execute_input":"2025-02-20T22:09:07.093694Z","iopub.status.idle":"2025-02-20T22:09:07.166328Z","shell.execute_reply.started":"2025-02-20T22:09:07.093664Z","shell.execute_reply":"2025-02-20T22:09:07.165429Z"}},"outputs":[{"name":"stdout","text":"b'imagine being able to know the emotions of students during class, such as when they are bored, or when they are confused. that\\'s what the new facial action coding system would active. this kind of technology in the classrooms would be a necessity for teacher to effects teach to their students, and identify when they need help, or when they are getting bored during their lesson.\\n\\nstudents get bored during class, and don\\'t pay attention because of that. students also get confused during class, but sometimes a bored student can get confused with a student that is confused on what the teacher is taking about and needs help. the facs would change that, because teacher would be able to analyze whether their students are either board or confused, or enjoying their lessons. it would also help teacher identify which lessons their students are enjoying, and would be able to use that data to plan which lessons to include, and which lessons or activity to throw away became they are boring and would not do the their students any good.\"\\' a classroom computer could recognize when a student is becoming confused or bored,\\' dr hung predicts \\'then, it could modify the lesson, like an effective human instructor\"\\' (d\\'alto). meaning that the facs can help with digital lessons too, improving the effecting of them as well. another aspect for the facs, is that it can help students learn more about identifying emotions. \"to and expert, faces don\\'t lie; these muscles clues are sometimes used to spot when a \\'smiling\\' politician or celebrity isn\\'t being truthful\" (d\\'alto). this technology can spark an interest in psychology in students making the more interested in leading about emotions and how they can identify them in their peers. it can also case students to be interested in the technology behind it all. \"his new computer software stores similar anatomical information as electronic code\" (d\\'alto). this can also spark an interest in coding and working with computers.\\n\\nthere, the facs will be a valuable tool for reaching in the classroom, for both the teachers, and the students. people assume tht students do bad in school because they don\\'t pay attention, but this is usually because the lessons are either confusing or boring.'\n0.0\n\nb'is tee use of a new technology called tee facial action coding system valuable to read tee emotional expressions of students in a classroom?. in tee article \"making mona lisa smile\" by nick d\\'alto, tee author describes now a new technology called tee facial action coding system enables computer to identify human emotions. it is a new software teat ea\\'s been developed teat improves accuracy in perceiving tee emotions of others, and, ea\\'s promising applications for a variety of industries. tee use of this new technology is valuable to read tee emotional expressions of students in a classroom because it recognizes whether a student is boring or confused, it detects 6 basic emotions and even mixed and it eels tee person not only to express tee emotions but to produce teem.\\n\\nschool brings a lot of emotions to tee students, tea might be good or bad feelings. but tee most common feelings seen by tee teachers are boredom, and confusion from tee students, sometimes tee teachers are not able to identify those emotions, since students just might fake a smile and tee teacher will be satisfied teat tee student is doing just fine or teeny might be confused but afraid to speak up so tea just sit tear like everything is just normal. so, now might tee teacher be able to identify these emotions? tee facial action coding system ea\\'s tee answer. in tee passage it states \"a classroom computer could recognize ween a student is becoming confused or bored\". it also states \"teen it could modify tee lesson, like an effective e human instructor\". by this evidence, tee author tries to persuade tee reader to get more into this new technology and now it is just not a software but a valuable being. with this technology it would be easier for tee teacher to identify ween one or more students are bored; this would allow teem to think through about changing a new method to peace so tee students don\\'t get bored in class. it also helps teem to notify ween a student is confused on a topic, so tee teacher would be able to take tee necessary time to explain and explain until tee student is able to understand tee new topic learned. tee majority of students nowadays don\\'t care about school or just don\\'t get tee new topic learned, but teachers try tear best to help teem, but tea think everything is just fine, so tea don\\'t bother on asking or trying harder. communication is tee key to success but tea don\\'t implement it, sow eat is best team a new technology to help out a little.\\n\\ntear are 6 basic emotions; happiness, surprise, anger, disgust, fear, and sadness and tear are even people teat eave not only one but two mixed emotions at tee same time. wouldn\\'t it be great to be able to recognize ween a person is having these emotions?. this new technology is ear to help. in tee passage it states \"beckman ea\\'s classified six basic emotions... and teen associated with characteristic movements of tee facial muscles\". it also states \"tee software can even identify mixed emotions (as in da vinci\\'s masterpiece). each expression is compared against a neutral face(showing no emotion)\". this evidence illustrates by tee author shows now great and advanced this technology is, being able to identify not only one emotion, but more team one at tee same time, letting tee world know, but most important tee teachers in a classroom teat tea don\\'t eave to worry more about to be able to identify by guessing now a student is doing, because this technology ea\\'s tee answers. it is so hard to identify ween a person is feeling all types of feelings and not be able to help out because no one knows what tee mixed feelings are. teachers eave a rouge time with students trying to figure it out. but with tes technology teachers would be more notified of tee problem, so tea create a scenario to help teem out.\\n\\nemotions are everywhere, everyone experiences at least one of teem. this new technology not only helps tee person to express an emotion but to produce teem. a teacher in a classroom is able to peace but sometimes tea are not able to transmit tee feeling of leading to tee students, and tee new technology facial action coding system would be a lot of help. in tee passage it states \"tee mona lisa is really intended to bring a smile to your face, while it shows just now much this computer can do\". it also states \"most human communication is nonverbal, including emotional communication\". by this evidence tee author projects now this new technology is capable of doing just anything and now it eels to improve tee best on a classroom, helping out not only tee students but tee teachers. with this new technology teachers would be able to get tee students to be more interested in tee class, leading teem to get a good grade, and to tee understanding of every new topic.\\n\\nnow, do you think this new technology called tee facial action coding system is valuable to read tee emotional expressions of students in a classroom?. by being able to detect 6 basic emotions and even mixed emotions, to recognize whether a student is bored or confused and by helping tee person not only to express tee emotion but to produce it, it is shown teat this new technology is valuable. communication is one of tee basic steps to create a better living world, but sometimes communication is just not implemented in society. so tee help of this new technology is needed. a teacher would be able to help a student is tea knew if tee students wear confused or bored. tea would try different types of ways to get back tee attention of tee students so tea can do good in tee calls. another reason is being able not only to know one emotion but multiple emotions; teachers wouldn\\'t eave to be guessing tee emotions of tee students, and tee time lose trying to guess tear emotions, tea would be finding ways to help tee student solve tear problem, because tea already know what is going on. in tee classrooms it is very hard for tee students to concentrate in a very boring topic, and tee teachers just will continue became tee students just don\\'t communicate or show anything else team just a black emotion and this new technology is able to get tee person to express tee emotion. is fascinating what this technology can do.  '\n0.0\n\nb\"technology has come sr far, over the years, that nrw students have the return try enroll in online school. online school is rne rf the many new technological advances that allows students try have an nontraditional way rf earning an education. having distance learning rr online school is beneficial because it allows students try focus in an environment they feel comfortable in and it allows students try learn at their own pace.\\n\\nonline school allows students try learn in an environment they are comfortable in. imagine having a school that has a art rf loud, annoying, and mean students that dr nrt like try dr their work. nrw imagine placing a straight a student in the middle rf that school. the student would nrt be able try focus, they would nrt feel comfortable, and they would be stressed about other students, constantly. teens and children are very influential rf each other, and when a large majority rf students dr nrt dr their work, the straight a student will most likely slip in that habit sr that they will fit in. nrw that straight a student went from trp rf their class try barely passing algebra. insuring a student, who wants try learn, feels comfortable in a learning environment is crucial try the student's success.\\n\\nhaving online schools allows students the opportunity try learn at their own pace. however, some people believe that it is better try keep all students learning the same material at the same time. the disadvantage try this is that nrt everyone learns at the same pace, and some students need more time in certain subjects than others. if a student wants try finish all their math classes in a week, they should have the return try dr that. if a student would benefit from having more time try practice rhetorical analysis, then the student should be able try get that practice. allowing students try charge their own pace rf learning will ultimately make them more successful in school because if they aren't during well in a subject, they have time try practice until they are able try succeed.\\n\\nin conclusion, students should have the opportunity try dr nontraditional\\xc2\\xa0online school because it will encourage them try learn in a more comfortable environment and it allows students try learn at their own pace. in addition, students would be able try stay home and wear pajamas all day. what student would nrt want that?\"\n0.0\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"#Calculate Vocabulary Size\nvocabulary = set()\ntrain_df['text'].str.lower().str.split().apply(vocabulary.update)\nvocabulary_size = len(vocabulary)\nprint(vocabulary_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:09:08.611371Z","iopub.execute_input":"2025-02-20T22:09:08.611656Z","iopub.status.idle":"2025-02-20T22:09:47.865699Z","shell.execute_reply.started":"2025-02-20T22:09:08.611634Z","shell.execute_reply":"2025-02-20T22:09:47.864782Z"}},"outputs":[{"name":"stdout","text":"437885\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"reserved_tokens = [\"[PAD]\", \"[UNK]\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:09:47.866842Z","iopub.execute_input":"2025-02-20T22:09:47.867068Z","iopub.status.idle":"2025-02-20T22:09:47.870441Z","shell.execute_reply.started":"2025-02-20T22:09:47.867048Z","shell.execute_reply":"2025-02-20T22:09:47.869475Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def train_word_piece(ds, vocab_size, reserved_tokens):\n    word_piece_ds = ds.unbatch().map(lambda x, y: x)\n    vocab = compute_word_piece_vocabulary(\n        word_piece_ds.batch(1024).prefetch(2),\n        vocabulary_size=vocabulary_size,\n        reserved_tokens=reserved_tokens,\n    )\n    return vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:09:47.871775Z","iopub.execute_input":"2025-02-20T22:09:47.871987Z","iopub.status.idle":"2025-02-20T22:09:47.884980Z","shell.execute_reply.started":"2025-02-20T22:09:47.871969Z","shell.execute_reply":"2025-02-20T22:09:47.884085Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"vocab = train_word_piece(train_dataset, vocabulary_size, reserved_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:09:47.886001Z","iopub.execute_input":"2025-02-20T22:09:47.886291Z","iopub.status.idle":"2025-02-20T22:50:40.470791Z","shell.execute_reply.started":"2025-02-20T22:09:47.886269Z","shell.execute_reply":"2025-02-20T22:50:40.469655Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"print(f'Tokens: {vocab[24:101]}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:50:40.473098Z","iopub.execute_input":"2025-02-20T22:50:40.473371Z","iopub.status.idle":"2025-02-20T22:50:40.477726Z","shell.execute_reply.started":"2025-02-20T22:50:40.473347Z","shell.execute_reply":"2025-02-20T22:50:40.476833Z"}},"outputs":[{"name":"stdout","text":"Tokens: ['7', '8', '9', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '\\xa0', '¡', '¢', '£', '¨', '©', '«', '¬', '®', '°', '²', '´', '¶', '·', '¸', '¹', 'º', 'Á', 'Â', 'Ã', 'Å', 'É', 'Ë', 'Ñ', 'Ó', 'Ö', '×', 'ß', 'à', 'á', 'â']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"tokenizer = WordPieceTokenizer(\n    vocabulary = vocab,\n    lowercase = False,\n    sequence_length = MAX_SEQLEN,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:50:40.478689Z","iopub.execute_input":"2025-02-20T22:50:40.478981Z","iopub.status.idle":"2025-02-20T22:50:40.824107Z","shell.execute_reply.started":"2025-02-20T22:50:40.478951Z","shell.execute_reply":"2025-02-20T22:50:40.823400Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"input_sentence_ex = train_dataset.take(1).get_single_element()[0][0]\ninput_tokens_ex = tokenizer(input_sentence_ex)\n\nprint(\"Sentence: \", input_sentence_ex)\nprint(\"Tokens: \", input_tokens_ex)\nprint(\"Recovered text after detokenizing: \", tokenizer.detokenize(input_tokens_ex))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:50:40.825489Z","iopub.execute_input":"2025-02-20T22:50:40.825797Z","iopub.status.idle":"2025-02-20T22:50:40.914885Z","shell.execute_reply.started":"2025-02-20T22:50:40.825772Z","shell.execute_reply":"2025-02-20T22:50:40.914223Z"}},"outputs":[{"name":"stdout","text":"Sentence:  tf.Tensor(b'imagine being able to know the emotions of students during class, such as when they are bored, or when they are confused. that\\'s what the new facial action coding system would active. this kind of technology in the classrooms would be a necessity for teacher to effects teach to their students, and identify when they need help, or when they are getting bored during their lesson.\\n\\nstudents get bored during class, and don\\'t pay attention because of that. students also get confused during class, but sometimes a bored student can get confused with a student that is confused on what the teacher is taking about and needs help. the facs would change that, because teacher would be able to analyze whether their students are either board or confused, or enjoying their lessons. it would also help teacher identify which lessons their students are enjoying, and would be able to use that data to plan which lessons to include, and which lessons or activity to throw away became they are boring and would not do the their students any good.\"\\' a classroom computer could recognize when a student is becoming confused or bored,\\' dr hung predicts \\'then, it could modify the lesson, like an effective human instructor\"\\' (d\\'alto). meaning that the facs can help with digital lessons too, improving the effecting of them as well. another aspect for the facs, is that it can help students learn more about identifying emotions. \"to and expert, faces don\\'t lie; these muscles clues are sometimes used to spot when a \\'smiling\\' politician or celebrity isn\\'t being truthful\" (d\\'alto). this technology can spark an interest in psychology in students making the more interested in leading about emotions and how they can identify them in their peers. it can also case students to be interested in the technology behind it all. \"his new computer software stores similar anatomical information as electronic code\" (d\\'alto). this can also spark an interest in coding and working with computers.\\n\\nthere, the facs will be a valuable tool for reaching in the classroom, for both the teachers, and the students. people assume tht students do bad in school because they don\\'t pay attention, but this is usually because the lessons are either confusing or boring.', shape=(), dtype=string)\nTokens:  tf.Tensor(\n[1298  680  690  582  671  581  829  584  600  783  745   13  701  606\n  621  592  594 1353   13  603  621  592  594 1328   15  586    8   58\n  635  581  667  822  944 1115  677  605 1394   15  597 1294  584  689\n  585  581 1724  605  591   40 3430  589  725  582 1337 1318  582  599\n  600   13  583 1492  621  592  672  629   13  603  621  592  594  806\n 1353  783  599 1245   15  600  641 1353  783  745   13  583  673    8\n   59 1057  899  609  584  586   15  600  617  641 1328  783  745   13\n  610  922   40 1353  649  593  641 1328  602   40  649  586  587 1328\n  596  635  581  725  587  819  633  583  953  629   15  581 1120  605\n  738  586   13  609  725  605  591  690  582 2353 1004  599  600  594\n 1278 1871  603 1328   13  603 3259  599 1599   15  588  605  617  629\n  725 1492  660 1599  599  600  594 3259   13  583  605  591  690  582\n  668  586 1678  582 1470  660 1599  582 1668   13  583  660 1599  603\n  851  582 3529  868 1568  592  594 1977  583  605  598  613  581  599\n  600  719  665   15    3    8   40  856  842  623 1405  621   40  649\n  587 1208 1328  603 1353   13    8 1484 5784 4083    8  684   13  588\n  623 2334  581 1245   13  619  620 1225  772 2540    3    8    9   43\n    8 3133   10   15 1849  586  581 1120  593  629  602 2305 1599  793\n   13 1769  581 8133  584  626  606  710   15  716 1940  589  581 1120\n   13  587  586  588  593  629  600  698  604  633 3852  829   15    3\n  582  583 3227   13 1867  673    8   59 2759   28  658 1487 4844  594\n  922  810  582 2867  621   40    8 3197    8 5111  603 4915 1128    8\n   59  680 4355    3    9   43    8 3133   10   15  597  689  593 5429\n  620 1303  585 3612  585  600  743  581  604 1323  585 1296  633  829\n  583  650  592  593 1492  626  585  599 1609   15  588  593  617 1199\n  600  582  591 1323  585  581  689 1242  588  624   15    3  765  667\n  842 1243 2164 1233 7064  835  606 2394 2687    3    9   43    8 3133\n   10   15  597  593  617 5429  620 1303  585 1115  583  815  602 1230\n   15  615   13  581 1120  612  591   40  992 1829  589 3392  585  581\n  856   13  589  843  581  723   13  583  581  600   15  601 4008 2384\n  600  613  839  585  614  609  592  673    8   59 1057  899   13  610\n  597  587 1499  609  581 1599  594 1278 3466  603 1977   15    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0], shape=(512,), dtype=int32)\nRecovered text after detokenizing:  imagine being able to know the emotions of students during class , such as when they are bored , or when they are confused . that ' s what the new facial action coding system would active . this kind of technology in the classrooms would be a necessity for teacher to effects teach to their students , and identify when they need help , or when they are getting bored during their lesson . students get bored during class , and don ' t pay attention because of that . students also get confused during class , but sometimes a bored student can get confused with a student that is confused on what the teacher is taking about and needs help . the facs would change that , because teacher would be able to analyze whether their students are either board or confused , or enjoying their lessons . it would also help teacher identify which lessons their students are enjoying , and would be able to use that data to plan which lessons to include , and which lessons or activity to throw away became they are boring and would not do the their students any good . \" ' a classroom computer could recognize when a student is becoming confused or bored , ' dr hung predicts ' then , it could modify the lesson , like an effective human instructor \" ' ( d ' alto ) . meaning that the facs can help with digital lessons too , improving the effecting of them as well . another aspect for the facs , is that it can help students learn more about identifying emotions . \" to and expert , faces don ' t lie ; these muscles clues are sometimes used to spot when a ' smiling ' politician or celebrity isn ' t being truthful \" ( d ' alto ) . this technology can spark an interest in psychology in students making the more interested in leading about emotions and how they can identify them in their peers . it can also case students to be interested in the technology behind it all . \" his new computer software stores similar anatomical information as electronic code \" ( d ' alto ) . this can also spark an interest in coding and working with computers . there , the facs will be a valuable tool for reaching in the classroom , for both the teachers , and the students . people assume tht students do bad in school because they don ' t pay attention , but this is usually because the lessons are either confusing or boring . [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"def format_dataset(sentence, label):\n    sentence = tokenizer(sentence)\n    return ({\"input_ids\": sentence}, label)\n\ndef make_dataset(dataset):\n    dataset = dataset.map(format_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n    return dataset.shuffle(BATCH_SIZE * 8).prefetch(16).cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:50:40.915698Z","iopub.execute_input":"2025-02-20T22:50:40.915940Z","iopub.status.idle":"2025-02-20T22:50:40.920383Z","shell.execute_reply.started":"2025-02-20T22:50:40.915907Z","shell.execute_reply":"2025-02-20T22:50:40.919423Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"train_dataset = make_dataset(train_dataset)\nval_dataset = make_dataset(val_dataset)\ntest_dataset = make_dataset(test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:50:40.921144Z","iopub.execute_input":"2025-02-20T22:50:40.921424Z","iopub.status.idle":"2025-02-20T22:50:41.877891Z","shell.execute_reply.started":"2025-02-20T22:50:40.921403Z","shell.execute_reply":"2025-02-20T22:50:41.877211Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"EMBED_DIM = 128\nINTERMEDIATE_DIM = 4 * EMBED_DIM","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:50:41.878651Z","iopub.execute_input":"2025-02-20T22:50:41.878883Z","iopub.status.idle":"2025-02-20T22:50:41.882476Z","shell.execute_reply.started":"2025-02-20T22:50:41.878862Z","shell.execute_reply":"2025-02-20T22:50:41.881679Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from tensorflow.keras import layers, regularizers, optimizers, Model\nfrom tensorflow.keras.layers import LSTM, Dense, Input\nfrom tensorflow.keras.models import Model\n\ndef create_model(vocabulary_size):\n    input_ids = Input(shape=(512,), dtype=\"int64\", name=\"input_ids\")\n    \n    # Embedding layer with masking\n    x = TokenAndPositionEmbedding(\n        vocabulary_size=vocabulary_size,\n        sequence_length=512,\n        embedding_dim=128,\n        mask_zero=False,\n    )(input_ids)\n\n   \n    # Bidirectional LSTM with explicit mask\n    x = layers.Bidirectional(\n        layers.LSTM(\n            32,\n            activation=\"tanh\",\n            kernel_regularizer=regularizers.l2(0.001),\n            use_cudnn=False\n        )\n    )(x)\n\n    # Dense layer for binary classification\n    outputs = Dense(1, activation=\"sigmoid\")(x)\n\n    # Compile the model\n    model = Model(input_ids, outputs, name=\"BiEscalator\")\n    model.compile(\n        optimizer=optimizers.Adam(learning_rate=3e-4),\n        loss=\"binary_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T23:06:41.308001Z","iopub.execute_input":"2025-02-20T23:06:41.308303Z","iopub.status.idle":"2025-02-20T23:06:41.314219Z","shell.execute_reply.started":"2025-02-20T23:06:41.308279Z","shell.execute_reply":"2025-02-20T23:06:41.313393Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"## Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"'''import keras_tuner as kt\ntuner = kt.BayesianOptimization(\n    hypermodel = create_model,\n    objective = 'val_loss',\n    overwrite = True,\n    max_trials = 10\n)\ntuner.search(train_dataset, validation_data = val_dataset, epochs = 10, verbose = 1)'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T22:51:52.616714Z","iopub.execute_input":"2025-02-20T22:51:52.617029Z","iopub.status.idle":"2025-02-20T22:51:52.622162Z","shell.execute_reply.started":"2025-02-20T22:51:52.616997Z","shell.execute_reply":"2025-02-20T22:51:52.621425Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"\"import keras_tuner as kt\\ntuner = kt.BayesianOptimization(\\n    hypermodel = create_model,\\n    objective = 'val_loss',\\n    overwrite = True,\\n    max_trials = 10\\n)\\ntuner.search(train_dataset, validation_data = val_dataset, epochs = 10, verbose = 1)\""},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"# Modelling RAHHHHH\n","metadata":{}},{"cell_type":"code","source":"Sherlock = create_model(29383)\nSherlock.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T23:06:51.060224Z","iopub.execute_input":"2025-02-20T23:06:51.060508Z","iopub.status.idle":"2025-02-20T23:06:51.128430Z","shell.execute_reply.started":"2025-02-20T23:06:51.060486Z","shell.execute_reply":"2025-02-20T23:06:51.127770Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"BiEscalator\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"BiEscalator\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ token_and_position_embedding_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m3,826,560\u001b[0m │\n│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)          │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m41,216\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ token_and_position_embedding_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,826,560</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)          │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,867,841\u001b[0m (14.75 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,867,841</span> (14.75 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,867,841\u001b[0m (14.75 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,867,841</span> (14.75 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"mask = Sherlock.layers[1].compute_mask(train_dataset)\nprint(mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T23:07:33.803883Z","iopub.execute_input":"2025-02-20T23:07:33.804156Z","iopub.status.idle":"2025-02-20T23:07:33.809225Z","shell.execute_reply.started":"2025-02-20T23:07:33.804136Z","shell.execute_reply":"2025-02-20T23:07:33.808340Z"}},"outputs":[{"name":"stdout","text":"None\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"reduceLR = keras.callbacks.ReduceLROnPlateau(\n    monitor = \"val_loss\",\n    factor = 0.0973,\n    patience = 3,\n    verbose = 1,\n    mode = \"auto\",\n    min_delta = 1e-4,\n    cooldown = 0,\n    min_lr = 0,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T23:07:35.465446Z","iopub.execute_input":"2025-02-20T23:07:35.465748Z","iopub.status.idle":"2025-02-20T23:07:35.469747Z","shell.execute_reply.started":"2025-02-20T23:07:35.465724Z","shell.execute_reply":"2025-02-20T23:07:35.468916Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"earlyStop = keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    min_delta = 0.001,\n    patience = 10,\n    verbose = 1,\n    mode = \"auto\",\n    restore_best_weights = True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T23:07:36.593251Z","iopub.execute_input":"2025-02-20T23:07:36.593574Z","iopub.status.idle":"2025-02-20T23:07:36.597771Z","shell.execute_reply.started":"2025-02-20T23:07:36.593549Z","shell.execute_reply":"2025-02-20T23:07:36.596876Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"history = Sherlock.fit(\n    train_dataset,\n    epochs=50, \n    validation_data=val_dataset,\n    callbacks=[earlyStop, reduceLR]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T23:07:36.868831Z","iopub.execute_input":"2025-02-20T23:07:36.869119Z","iopub.status.idle":"2025-02-20T23:59:44.469794Z","shell.execute_reply.started":"2025-02-20T23:07:36.869093Z","shell.execute_reply":"2025-02-20T23:59:44.468496Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m27407/27407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m780s\u001b[0m 28ms/step - accuracy: 0.9685 - loss: 0.1071 - val_accuracy: 0.9967 - val_loss: 0.0143 - learning_rate: 3.0000e-04\nEpoch 2/50\n\u001b[1m27407/27407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m749s\u001b[0m 27ms/step - accuracy: 0.9946 - loss: 0.0201 - val_accuracy: 0.9972 - val_loss: 0.0115 - learning_rate: 3.0000e-04\nEpoch 3/50\n\u001b[1m27407/27407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m748s\u001b[0m 27ms/step - accuracy: 0.9967 - loss: 0.0123 - val_accuracy: 0.9982 - val_loss: 0.0083 - learning_rate: 3.0000e-04\nEpoch 4/50\n\u001b[1m27407/27407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m747s\u001b[0m 27ms/step - accuracy: 0.9969 - loss: 0.0122 - val_accuracy: 0.9959 - val_loss: 0.0139 - learning_rate: 3.0000e-04\nEpoch 5/50\n\u001b[1m 3875/27407\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:26\u001b[0m 27ms/step - accuracy: 0.9984 - loss: 0.0063","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-331e9f106e9a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = Sherlock.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlyStop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduceLR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":41},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_result(item):\n    plt.plot(history.history[item], label=item)\n    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(item)\n    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n    plt.legend()\n    plt.grid()\n    plt.show()\n\n\nplot_result(\"loss\")\nplot_result(\"accuracy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T23:59:48.173576Z","iopub.execute_input":"2025-02-20T23:59:48.173879Z","iopub.status.idle":"2025-02-20T23:59:48.200532Z","shell.execute_reply.started":"2025-02-20T23:59:48.173855Z","shell.execute_reply":"2025-02-20T23:59:48.199548Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-00ba40e5a6ae>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mplot_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mplot_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-42-00ba40e5a6ae>\u001b[0m in \u001b[0;36mplot_result\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"],"ename":"NameError","evalue":"name 'history' is not defined","output_type":"error"}],"execution_count":42},{"cell_type":"code","source":"Sherlock.evaluate(test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T00:00:04.610855Z","iopub.execute_input":"2025-02-21T00:00:04.611134Z","iopub.status.idle":"2025-02-21T00:00:24.646404Z","shell.execute_reply.started":"2025-02-21T00:00:04.611112Z","shell.execute_reply":"2025-02-21T00:00:24.645691Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1523/1523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9981 - loss: 0.0077\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"[0.00760191585868597, 0.9979886412620544]"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}